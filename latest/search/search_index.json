{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"HPCQC Hybrid Stack Documentation","text":"<p>[!NOTE] Testing first version deploy.</p> <p>This repository provides the architectural and design documentation for the Hybrid High-Performance Computing and Quantum Computing (HPCQC) Stack, currently under development as part of a research proposal. Covers the software architecture and runtime design. The documentation defines the conceptual, logical, and technical foundations of a hybrid runtime that integrates classical HPC resources with quantum backends under a unified software stack. It focuses on design rationale, interoperability between ecosystems, and formal reproducibility of hybrid workflows.</p> <p>This document focuses solely on the software stack and the runtime orchestration layer, i.e., the components that enable execution, scheduling, data management, and observability in an HPCQC backend. Therefore, this documentation does not cover the theoretical framework of space-time circuit knitting, which constitutes the scientific foundation motivating this proposal. This framework considers that a quantum circuit can be decomposed into subcircuits that can be analysed and redirected to heterogeneous backends. Certain partitions are executed on HPC nodes with classical computing, while others are executed on QPU nodes or quantum clouds. In this way, we understand that bidirectional optimization is achieved.</p> <p>First, temporal optimization is achieved through malleability \u2014dynamically resizing MPI teams during QPU idle phases (a concept introduced in Rocco et al. (2025)<sup>1</sup>). Specifically, classical idle nodes are minimized to \\(k\\) nodes; where \\(k\\) nodes correspond to each active node executing the computation of a subcircuit.</p> <p>Second, spatial optimization is achieved through hybrid executions using HPC as an active classical coprocessor for subcircuits under the MPI paradigm. It is understood that classical computing can push the limits of NISQ quantum computers by offloading circuit depth.</p> <p>Therefore, this documentation should be read as an engineering realization \u2014pre-alpha phase\u2014 of these theoretical ideas: how the proposed runtime, middleware, and scheduler are designed to operationalize space-time circuit knitting in a reproducible, scalable, and cluster-compatible way.</p>"},{"location":"#purpose-and-scope","title":"Purpose and Scope","text":"<p>This documentation serves as a design baseline for the future prototype. It records the reasoning, assumptions, and interface contracts that will guide the implementation once the research moves into the development phase. It will also serve as an architectural decision record so that the reasons behind certain decisions can be reviewed in the future\u2014offering traceability and transparency.</p> <p>At this stage:</p> <ul> <li>The project is in the proposal and design phase, not implementation.</li> <li>No software versions are yet defined.</li> <li>The documentation reflects the intended architecture, specifications, and decisions.</li> <li>All components are currently conceptual.</li> <li>Validation will use HPC simulators and limited QPU-cloud time.</li> </ul> <p>When coding begins, this repository will evolve to include:</p> <ul> <li>SBOM (Software Bill of Materials) for dependency governance and reproducibility.</li> <li>RACI matrix defining roles and responsibilities in the development workflow.</li> <li>Version tracking and release notes once the runtime reaches alpha status.</li> </ul>"},{"location":"#high-level-architecture-summary","title":"High-Level Architecture Summary","text":"<pre><code>%%{init: {'layout': 'elk', 'theme': 'neutral', 'flowchart': {'useMaxWidth': true}}}%%\n\nflowchart TB\n  %% ===== Capas =====\n  subgraph L0[\"Applications and Users\"]\n    U1[\"HPC QC User Apps\"]\n    U2[\"CLI and Python Bindings\"]\n  end\n\n  subgraph L1[\"Frontends and Quantum Formats\"]\n    F1[\"Qiskit Cirq Braket\"]\n    F5[\"QASM3 Parser C++ ANTLR4\"]\n  end\n\n  subgraph L2[\"Internal IR and Analysis\"]\n    IR1[\"Space Time DAG\"]\n    IR3[\"Annotations and Metadata\"]\n  end\n\n  subgraph L3[\"Partitioning and Models\"]\n    P1[\"Wire Cuts and Time Cuts\"]\n    M1[\"Cost Model Tq Tc Comm\"]\n    M2[\"Fidelity Bound DeltaF\"]\n  end\n\n  subgraph L4[\"Scheduler and Middleware\"]\n    S1[\"Malleable HEFT Scheduler\"]\n    X2[\"RMS Adapter Slurm HyperQueue PBS\"]\n  end\n\n  subgraph L5[\"Hybrid Runtime\"]\n    R1[\"C++ API and Py Bindings\"]\n    R4[\"Transport gRPC REST\"]\n    R5[\"Tensor Plane and Checkpoints HDF5\"]\n  end\n\n  subgraph L6[\"HPC Backends\"]\n    H1[\"MPI OpenMP OmpSs 2\"]\n    H3[\"CUDA NCCL\"]\n    H5[\"cuTensorNet cuBLAS\"]\n  end\n\n  subgraph L7[\"Quantum Backends\"]\n    Q1[\"IBM Runtime AWS Braket IonQ\"]\n    Q5[\"Simulators Aer cuQuantum\"]\n  end\n\n  subgraph L8[\"Observability\"]\n    O1[\"JSONL Logs\"]\n    O2[\"Metrics S p Ep chi Fidelity\"]\n    O3[\"Profiling Nsight mpiP Scalasca\"]\n  end\n\n  %% ===== Flujo principal =====\n  U1 --&gt; U2\n  U2 --&gt; F1\n  F1 --&gt; F5\n  F5 --&gt; IR1\n  IR1 --&gt; IR3\n  IR3 --&gt; P1\n  P1 --&gt; M1\n  P1 --&gt; M2\n  M1 --&gt; S1\n  M2 --&gt; S1\n  S1 --&gt; X2\n  S1 --&gt; R1\n  R1 --&gt; R4\n  R1 --&gt; R5\n\n  %% Ejecucion clasica\n  R1 --&gt; H1\n  H1 --&gt; H3\n  H3 --&gt; H5\n  H5 --&gt; R5\n\n  %% Ejecucion cuantica\n  R4 --&gt; Q1\n  R1 --&gt; Q5\n  Q1 --&gt; R5\n  Q5 --&gt; R5\n\n  %% Observabilidad lateral\n  R1 --&gt; O1\n  H1 --&gt; O3\n  H3 --&gt; O3\n  R5 --&gt; O2\n  Q1 --&gt; O2\n\n  %% Retroalimentacion de modelos\n  O2 --&gt; S1\n  O3 --&gt; S1</code></pre> <p>The stack structure begins with circuit submission via CLI or Python bindings. Frontends are normalized to QASM3, and the peer generates an annotated IR Space-Time DAG. The partitioner applies wire cuts and time cuts and produces \\(T_q\\), \\(T_c\\) \\(\\text{Comm}\\) costs and a \\(\\Delta_F\\) fidelity bound. The malleable HEFT scheduler schedules waves, requests resources from the RMS, and orchestrates the runtime. Classical subcircuits run on MPI OpenMP OmpSs 2 with CUDA NCCL and are assembled using tensor contraction with cuTensorNet and cuBLAS. Quantum subcircuits are submitted to IBM Runtime, AWS Braket, or IonQ, and Aer cuQuantum simulators complement testing and validation. The data plane persists tensor shots and checkpoints in HDF5. Observability collects logs, metrics, and profiles and provides feedback to the scheduler to recalibrate weights and windows.</p>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"Section Description C4 Architecture Views Multi-level system diagrams (Context \u2192 Container \u2192 Component \u2192 Deployment \u2192 Scenario). Architecture Decision Records (ADRs) Formalized design decisions following the Nygard ADR pattern. RFCs Detailed technical specifications and protocols that complement the ADRs."},{"location":"#what-this-documentation-includes","title":"What This Documentation Includes","text":"<ul> <li>Conceptual architecture: high-level vision of the hybrid HPC\u2013QC system and its interfaces.  </li> <li>Technical architecture: internal models such as the IR (Intermediate Representation), cost and fidelity models, partitioning heuristics, and runtime orchestration.  </li> <li>Operational view: scheduling policies, deployment workflows, monitoring and observability design.  </li> <li>Scientific validation: benchmark design for the molecular nitrogen (\\(N_2\\)) case study.</li> </ul>"},{"location":"#future-additions","title":"Future Additions","text":"<p>As the project transitions to implementation, this documentation will expand to include:</p> <ul> <li>SBOM and dependency transparency for all toolchains (C++, MPI, CUDA, pybind11, etc.).  </li> <li>RACI matrices defining engineering, QA, and research responsibilities.  </li> <li>Testing and CI/CD guides for reproducible deployment on BSC clusters.  </li> <li>Release documentation aligned with semantic versioning once artifacts exist.</li> </ul>"},{"location":"#additional-information","title":"Additional Information","text":"<ul> <li>Created by: Ricard Santiago Raigada Garc\u00eda</li> <li>Advised by: Dr. Sergio Iserte Agut</li> <li>Reviewed by: Dr. Sergio Iserte Agut</li> <li>Lifecycle: Research design baseline</li> <li>Versioning: This documentation is versioned using Mike</li> </ul> <p>Status: Research design phase \u2014 pre-alpha</p> <p>This documentation evolves alongside the research. All diagrams, ADRs, and RFCs are living documents and may change as prototypes and experiments mature.</p> <ol> <li> <p>Rocco, R., Rizzo, S., Barbieri, M., Bettonte, G., Boella, E., Ganz, F., Iserte, S., Pe\u00f1a, A. J., Sand\u00e5s, P., Scionti, A., Terzo, O., Vercellino, C., Vitali, G., Viviani, P., Frassineti, J., Marzella, S., Ottaviani, D., Colonnelli, I., &amp; Gregori, D. (2025, 6 agosto). Dynamic Solutions for Hybrid Quantum-HPC Resource Allocation. arXiv.org. https://arxiv.org/abs/2508.04217v1 \u21a9</p> </li> </ol>"},{"location":"adr/","title":"ADR Index","text":"<p>This section collects all the Architecture Decision Records (ADRs) that define the rationale, trade-offs, and final choices made during the design of the hybrid HPCQC software stack.</p> <p>Each ADR follows the Michael Nygard pattern, represents a temporal and transparent record of the specific decisions made. Together, they ensure the long-term traceability and reproducibility of architectural reasoning.</p>"},{"location":"adr/#core-architecture-decisions","title":"Core Architecture Decisions","text":"<ul> <li>1. Record architecture decisions</li> <li>2. Product: Hybrid HPCQC middleware and runtime</li> <li>3. Base language and toolchain: C++23 + MPI + CUDA</li> <li>4. Quantum exchange format: OpenQASM 3</li> <li>5. QASM3 parser with ANTLR4 in C++</li> <li>6. Internal IR: space\u2013time DAG with annotations</li> <li>7. Partition policy: wire cuts and time cuts</li> </ul>"},{"location":"adr/#modeling-and-scheduling","title":"Modeling and Scheduling","text":"<ul> <li>8. Cost and fidelity model</li> <li>9. Malleable HEFT scheduler</li> <li>14. RMS integration: Slurm, HyperQueue, PBS</li> </ul>"},{"location":"adr/#runtime-and-execution-layer","title":"Runtime and Execution Layer","text":"<ul> <li>10. QPU transport and backends: REST gRPC</li> <li>11. Tensor contraction stitching: cuBLAS and cuTensorNet</li> <li>12. Storage and checkpointing: HDF5 with MPI-IO</li> <li>15. Python bindings with pybind11</li> </ul>"},{"location":"adr/#observability-data-and-security","title":"Observability, Data, and Security","text":"<ul> <li>13. Observability: logging, metrics, and profiling</li> <li>19. QPU credential security and management</li> <li>24. Structured JSONL logs and wave IDs</li> </ul>"},{"location":"adr/#deployment-and-portability","title":"Deployment and Portability","text":"<ul> <li>16. No Chapel, Charm++, or UPC in core</li> <li>17. NCCL for multi-GPU intra-node</li> <li>18. Global Arrays or OpenSHMEM as optional</li> <li>20. Containers and reproducibility with Apptainer</li> </ul>"},{"location":"adr/#validation-and-configuration","title":"Validation and Configuration","text":"<ul> <li>21. Benchmark selection: \\(N_2\\) and metrics</li> <li>22. QPU cloud usage limits</li> <li>23. Configuration and contracts in YAML</li> </ul>"},{"location":"adr/0001-record-architecture-decisions/","title":"1. Record architecture decisions","text":"<p>Date: 2025-10-13</p>"},{"location":"adr/0001-record-architecture-decisions/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"adr/0001-record-architecture-decisions/#context","title":"Context","text":"<p>We need to record the architectural decisions made on this project.</p>"},{"location":"adr/0001-record-architecture-decisions/#decision","title":"Decision","text":"<p>We will use Architecture Decision Records, as described by Michael Nygard.</p>"},{"location":"adr/0001-record-architecture-decisions/#consequences","title":"Consequences","text":"<p>See Michael Nygard's article, linked above. For a lightweight ADR toolset, see Nat Pryce's adr-tools.</p>"},{"location":"adr/0002-hybrid-hpc-qc-middleware-and-runtime-product/","title":"2. Product: Hybrid HPCQC middleware and runtime","text":"<p>Date: 2025-10-13</p>"},{"location":"adr/0002-hybrid-hpc-qc-middleware-and-runtime-product/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"adr/0002-hybrid-hpc-qc-middleware-and-runtime-product/#context","title":"Context","text":"<p>The project must integrate quantum computing on QPUs and classical HPC computing, orchestrating spatiotemporal partitioning and tensor contraction, without modifying QPU firmware.</p>"},{"location":"adr/0002-hybrid-hpc-qc-middleware-and-runtime-product/#decision","title":"Decision","text":"<p>We define the product as hybrid HPCQC middleware + runtime:</p> <ul> <li>Middleware: partitioning, scheduling, orchestration with RMS, and telemetry.</li> <li>Runtime: Execution API, task queues, transport to QPUs, and data plane.</li> </ul>"},{"location":"adr/0002-hybrid-hpc-qc-middleware-and-runtime-product/#consequences","title":"Consequences","text":"<p>The scope is defined based on middleware/execution layer software, avoiding firmware layers and maximizing portability between vendors and HPC centers.</p>"},{"location":"adr/0003-base-language-and-toolchain-c-23-mpi-cuda/","title":"3. Base language and toolchain: C++23 + MPI + CUDA","text":"<p>Date: 2025-10-13</p>"},{"location":"adr/0003-base-language-and-toolchain-c-23-mpi-cuda/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"adr/0003-base-language-and-toolchain-c-23-mpi-cuda/#context","title":"Context","text":"<p>High performance, HPC portability, and GPU acceleration are required. BSC offers mature toolchains for C++, MPI, and CUDA.</p>"},{"location":"adr/0003-base-language-and-toolchain-c-23-mpi-cuda/#decision","title":"Decision","text":"<p>Use C++23 for the core, MPI for inter-node communication, and CUDA &gt;= 12.x for GPU kernels and libraries. Use OpenMP and OmpSs-2 for intra-node parallelism. Compilation handled with CMake.</p>"},{"location":"adr/0003-base-language-and-toolchain-c-23-mpi-cuda/#consequences","title":"Consequences","text":"<ul> <li>High performance and fine memory control.</li> <li>Natural integration with cuBLAS, cuTensorNet, and NCCL.</li> <li>More complex than Python for the core, but Python bindings will be provided at the outer layer.</li> </ul>"},{"location":"adr/0004-quantum-exchange-format-openqasm-3/","title":"4. Quantum exchange format: OpenQASM 3","text":"<p>Date: 2025-10-13</p>"},{"location":"adr/0004-quantum-exchange-format-openqasm-3/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"adr/0004-quantum-exchange-format-openqasm-3/#context","title":"Context","text":"<p>We need interoperability between Qiskit, Cirq, and Braket, and a standard representation for QPU submission.</p>"},{"location":"adr/0004-quantum-exchange-format-openqasm-3/#decision","title":"Decision","text":"<p>Adopt OpenQASM 3 as both input and output format toward providers. The internal parser will convert QASM3 to a lightweight proprietary Intermediate Representation (IR).</p>"},{"location":"adr/0004-quantum-exchange-format-openqasm-3/#consequences","title":"Consequences","text":"<ul> <li>Avoids dependency on specific SDKs.</li> <li>Preserves optimizations before partitioning.</li> <li>Simplifies transport to multiple backends.</li> </ul>"},{"location":"adr/0005-qasm3-parser-with-antlr4-in-c/","title":"5. QASM3 parser with ANTLR4 in C++","text":"<p>Date: 2025-10-13</p>"},{"location":"adr/0005-qasm3-parser-with-antlr4-in-c/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"adr/0005-qasm3-parser-with-antlr4-in-c/#context","title":"Context","text":"<p>The runtime must transform QASM3 into an internal IR for analysis and partitioning.</p>"},{"location":"adr/0005-qasm3-parser-with-antlr4-in-c/#decision","title":"Decision","text":"<p>Implement a QASM3 parser in C++ using ANTLR4, generating an abstract syntax tree (AST) and a space\u2013time DAG with annotations.</p>"},{"location":"adr/0005-qasm3-parser-with-antlr4-in-c/#consequences","title":"Consequences","text":"<ul> <li>Robust and extensible parser.</li> <li>Adds ANTLR4 dependency to the toolchain.</li> </ul>"},{"location":"adr/0006-internal-ir-space-time-dag-with-annotations/","title":"6. Internal IR: space\u2013time DAG with annotations","text":"<p>Date: 2025-10-13</p>"},{"location":"adr/0006-internal-ir-space-time-dag-with-annotations/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"adr/0006-internal-ir-space-time-dag-with-annotations/#context","title":"Context","text":"<p>An operational IR is required for partitioning, cost analysis, and scheduling without the complexity of LLVM at this stage.</p>"},{"location":"adr/0006-internal-ir-space-time-dag-with-annotations/#decision","title":"Decision","text":"<p>Define a space\u2013time DAG IR with annotations <code>space s</code> and <code>time t</code> and metadata fields like <code>depth</code>, <code>2Qcount</code>, <code>layout</code>, <code>error_est</code>.</p>"},{"location":"adr/0006-internal-ir-space-time-dag-with-annotations/#consequences","title":"Consequences","text":"<ul> <li>Lightweight and operational for scheduling.</li> <li>Easy to serialize, version, and audit.</li> </ul>"},{"location":"adr/0006-internal-ir-space-time-dag-with-annotations/#example","title":"Example","text":"<pre><code>{\n  \"nodes\": [\n    {\"id\":1, \"type\":\"cx\", \"qubits\":[0,1], \"space\":\"s0\", \"time\":0, \"cost\":{\"Tq\":0.15,\"Tc\":0,\"Comm\":0}},\n    {\"id\":2, \"type\":\"rz\", \"qubits\":[2],   \"space\":\"s1\", \"time\":0, \"cost\":{\"Tq\":0.05,\"Tc\":0,\"Comm\":0}},\n    {\"id\":3, \"type\":\"cx\", \"qubits\":[1,2], \"space_cross\":[\"s0\",\"s1\"], \"time\":1, \"cost\":{\"Tq\":0.20,\"Tc\":0,\"Comm\":0.02}}\n  ],\n  \"metadata\": {\"depth\":2, \"2Qcount\":2, \"fidelity_est\":0.997}\n}\n</code></pre>"},{"location":"adr/0007-partition-policy-wire-cuts-and-time-cuts/","title":"7. Partition policy: wire cuts and time cuts","text":"<p>Date: 2025-10-13</p>"},{"location":"adr/0007-partition-policy-wire-cuts-and-time-cuts/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"adr/0007-partition-policy-wire-cuts-and-time-cuts/#context","title":"Context","text":"<p>We need to reduce quantum depth and latency while maintaining fidelity.</p>"},{"location":"adr/0007-partition-policy-wire-cuts-and-time-cuts/#decision","title":"Decision","text":"<p>Apply wire cuts on low-correlation bipartitions and time cuts on trotterized sequences or temporal layers. Use heuristics based on crossed 2Q counts and entropy estimators.</p>"},{"location":"adr/0007-partition-policy-wire-cuts-and-time-cuts/#consequences","title":"Consequences","text":"<ul> <li>Controlled trade-off between fidelity and cost.</li> <li>Requires an explicit evaluation of the expected fidelity loss (\\(\\Delta F\\)) introduced by each cut, using conservative upper bounds to ensure that the overall circuit accuracy remains within the target error tolerance.</li> </ul>"},{"location":"adr/0008-cost-and-fidelity-model/","title":"8. Cost and fidelity model","text":"<p>Date: 2025-10-13</p>"},{"location":"adr/0008-cost-and-fidelity-model/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"adr/0008-cost-and-fidelity-model/#cost-model-m1","title":"Cost Model (M1)","text":"<p>The M1 model estimates the total time cost of executing a hybrid subcircuit (quantum + classical). For each node of the IR graph, three components are assigned:</p> <ul> <li>\\(T_q\\): estimated quantum execution time, obtained from the QPU backend or simulator (gate time, queue time, and dispatch latency).</li> <li>\\(T_c\\): estimated classical computation time, obtained by benchmarking CUDA kernels, tensor contraction, or GPU reduction.</li> <li>\\(\\text{Comm}\\): communication time or cost between nodes or devices (MPI, NCCL, or CPU-GPU transfer).</li> </ul> <p>The total cost is modeled as a weighted linear combination:</p> <p>\\(C(v)=\\alpha T_q(v) + \\beta T_c(v) + \\gamma \\text{Comm}(v)\\)</p> <p>where the coefficients \\(\\alpha\\), \\(\\beta\\), and \\(\\gamma\\) reflect the relative importance of each component depending on the context and are empirically calibrated through profiling.</p> <p>The planner's objective is to minimize the overall makespan by considering this composite cost, dynamically adjusting the weights based on telemetry (O2 and O3,see ADR #13).</p>"},{"location":"adr/0008-cost-and-fidelity-model/#fidelity-model-m2","title":"Fidelity Model (M2)","text":"<p>The M2 model estimates the fidelity loss induced by each spatial or temporal slice. Each partition introduces a bias \\(\\Delta F\\) that depends on:</p> <ul> <li>The number of 2Q gates crossing the slice (a proxy for correlation between subcircuits).</li> <li>The bipartition entropy estimated from the IR (a measure of entanglement).</li> <li>The local depth and backend noise (expected accumulated error).</li> </ul> <p>The model associates an upper bound \\(\\Delta F_{\\max}\\) with each cut, and the scheduler penalizes solutions where the total estimated fidelity exceeds a threshold.</p> <p>Both models are used together: M1 reports the time cost, and M2 imposes an accuracy constraint.</p> <p>The final scheduling seeks to minimize the total time without degrading fidelity beyond the allowed value.</p>"},{"location":"adr/0008-cost-and-fidelity-model/#consequences","title":"Consequences","text":"<ul> <li>Subcircuits can be quantitatively prioritized based on cost and fidelity.</li> <li>The HEFT scheduler has consistent information for making multi-objective decisions.</li> <li>Precise instrumentation and profiling are required to update the parameters \u03b1, \u03b2, \u03b3, and \\(\\Delta F\\).</li> </ul>"},{"location":"adr/0009-malleable-heft-scheduler/","title":"9. Malleable HEFT scheduler","text":"<p>Date: 2025-10-13</p>"},{"location":"adr/0009-malleable-heft-scheduler/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"adr/0009-malleable-heft-scheduler/#context","title":"Context","text":"<p>Subcircuits have heterogeneous costs and QPU windows. Overlapping classical and quantum computation is required.</p>"},{"location":"adr/0009-malleable-heft-scheduler/#decision","title":"Decision","text":"<p>Implement a malleable scheduler based on a modified HEFT algorithm, using dynamic MPI teams via <code>MPI_Comm_split</code>, critical-path priorities, and cost-weighted and energy-aware policies.</p> <ul> <li>Priorities by critical path and topological level,</li> <li>Dynamic MPI devices using MPI_Comm_split to adjust concurrency,</li> <li>Cost-weighted policy using \\(w = \\alpha T_q + \\beta T_c + \\gamma \\text{Comm}\\),</li> <li>Energy-aware policy to limit power consumption during peaks,</li> <li>Telemetry feedback for online reordering and device resizing.</li> </ul> <p>The alternative could be Charm++ Overdecomposition. Good task object migration, but complicates integration with existing Slurm and MPI.</p>"},{"location":"adr/0009-malleable-heft-scheduler/#consequences","title":"Consequences","text":"<ul> <li>Overlaps QPU\u2013HPC workloads and reduces idle time.</li> <li>Increases runtime team management complexity.</li> </ul>"},{"location":"adr/0010-qpu-transport-and-backends-rest-grpc/","title":"10. QPU transport and backends: REST gRPC","text":"<p>Date: 2025-10-13</p>"},{"location":"adr/0010-qpu-transport-and-backends-rest-grpc/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"adr/0010-qpu-transport-and-backends-rest-grpc/#context","title":"Context","text":"<p>Interaction with IBM Runtime, Braket, and IonQ requires remote calls and session/credential management.</p>"},{"location":"adr/0010-qpu-transport-and-backends-rest-grpc/#decision","title":"Decision","text":"<p>Use REST gRPC as the transport channel from the runtime to providers, with a backend-specific adapter and token management outside the MPI domain. REST gRPC is chosen to reduce latency at the risk of a tightly coupled service.</p>"},{"location":"adr/0010-qpu-transport-and-backends-rest-grpc/#consequences","title":"Consequences","text":"<ul> <li>Improved security through credential isolation.</li> <li>Requires provider-specific adaptation layer.</li> </ul>"},{"location":"adr/0011-tensor-contraction-stitching-cublas-and-cutensornet/","title":"11. Tensor contraction stitching: cuBLAS and cuTensorNet","text":"<p>Date: 2025-10-13</p>"},{"location":"adr/0011-tensor-contraction-stitching-cublas-and-cutensornet/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"adr/0011-tensor-contraction-stitching-cublas-and-cutensornet/#context","title":"Context","text":"<p>Post-cut reconstruction requires efficient GPU tensor contractions and distributed aggregation.</p>"},{"location":"adr/0011-tensor-contraction-stitching-cublas-and-cutensornet/#decision","title":"Decision","text":"<p>Use cuTensorNet for tensor contraction and cuBLAS for dense algebra. Use NVIDIA Collective Communication Library (NCCL) for intra-node all-reduce and MPI Iallreduce for inter-node reductions.</p>"},{"location":"adr/0011-tensor-contraction-stitching-cublas-and-cutensornet/#consequences","title":"Consequences","text":"<ul> <li>High GPU performance.</li> <li>Explicit CUDA and NCCL dependency.</li> </ul>"},{"location":"adr/0012-storage-and-checkpointing-hdf5-with-mpi-io/","title":"12. Storage and checkpointing: HDF5 with MPI-IO","text":"<p>Date: 2025-10-13</p>"},{"location":"adr/0012-storage-and-checkpointing-hdf5-with-mpi-io/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"adr/0012-storage-and-checkpointing-hdf5-with-mpi-io/#context","title":"Context","text":"<p>We need to persist shots, tensors, intermediate states, and reproducible checkpoints.</p>"},{"location":"adr/0012-storage-and-checkpointing-hdf5-with-mpi-io/#decision","title":"Decision","text":"<p>Use HDF5 with MPI-IO for parallel writes, versioning artifacts and execution metadata.</p>"},{"location":"adr/0012-storage-and-checkpointing-hdf5-with-mpi-io/#consequences","title":"Consequences","text":"<ul> <li>Enables reproducibility and fault-tolerant restart.</li> <li>Requires specialized I/O layer and dataset schemas.</li> </ul>"},{"location":"adr/0013-observability-logging-metrics-and-profiling/","title":"13. Observability: logging, metrics, and profiling","text":"<p>Date: 2025-10-13</p>"},{"location":"adr/0013-observability-logging-metrics-and-profiling/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"adr/0013-observability-logging-metrics-and-profiling/#context","title":"Context","text":"<p>Cut tuning and scheduling require detailed operational data.</p>"},{"location":"adr/0013-observability-logging-metrics-and-profiling/#decision","title":"Decision","text":"<ul> <li> <p>JSONL logging by wave and subcircuit Each log entry captures timestamps, subcircuit ID, space-time labels, node allocation, and outcome hashes. This enables deterministic reconstruction of executions and facilitates regression analysis.</p> </li> <li> <p>Metrics: \\(S\\) (speed), \\(p\\) (parallel efficiency), \\(E_p\\) (energy performance), \\(\\chi\\) (complementary occupancy), \\(F\\) (fidelity)</p> </li> <li>Profiling: Nsight, mpiP, Scalasca  </li> <li>Nsight Systems/Compute: GPU kernel occupancy, CUDA stream overlap, tensor contraction bottlenecks.</li> <li>mpiP: inter-node MPI traffic patterns, communication cost (Comm) correlation with M1 model.</li> <li> <p>Scalasca: call-path tracing and synchronization imbalance for identifying malleability limits.   Profiling is integrated into continuous integration for automatic sampling on representative runs.</p> </li> <li> <p>YAML config for reproducibility</p> </li> </ul>"},{"location":"adr/0013-observability-logging-metrics-and-profiling/#o2-o3-telemetry-and-feedback-loop","title":"O2 &amp; O3 Telemetry and Feedback Loop","text":"<p>The observability subsystem consists of two complementary components, O2 and O3, that together provide continuous performance insight and model feedback for the hybrid HPCQC runtime.</p> <ul> <li> <p>O2 collects high-level operational metrics \u2014 such as speedup (\\(S\\)), parallel efficiency (\\(p\\)) or energy performance (\\(E_p\\)). Offering a global view of how efficiently resources are used and how well the system balances quantum and classical workloads.</p> </li> <li> <p>O3 performs low-level profiling through tools like Nsight, mpiP, and Scalasca, capturing detailed traces of GPU kernels, MPI communication patterns, synchronization delays, and power consumption.</p> </li> </ul> <p>This enables adaptive scheduling, improved parameter stability, and evidence-driven performance tuning without manual intervention, ensuring that the runtime remains consistent with real hardware behavior under varying load and quantum-device conditions.</p>"},{"location":"adr/0013-observability-logging-metrics-and-profiling/#consequences","title":"Consequences","text":"<ul> <li>Evidence-based improvement cycles.</li> <li>Controlled telemetry overhead.</li> </ul>"},{"location":"adr/0014-rms-integration-slurm-hyperqueue-pbs/","title":"14. RMS integration: Slurm, HyperQueue, PBS","text":"<p>Date: 2025-10-13</p>"},{"location":"adr/0014-rms-integration-slurm-hyperqueue-pbs/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"adr/0014-rms-integration-slurm-hyperqueue-pbs/#context","title":"Context","text":"<p>Execution at BSC-CNS and similar environments requires integration with resource managers.</p>"},{"location":"adr/0014-rms-integration-slurm-hyperqueue-pbs/#decision","title":"Decision","text":"<p>Implement an RMS adapter for Slurm first, with extensions for HyperQueue and PBS. Support heterogeneous reservations and srun/sbatch launchers.</p>"},{"location":"adr/0014-rms-integration-slurm-hyperqueue-pbs/#consequences","title":"Consequences","text":"<ul> <li>Standard deployment in HPC environments.</li> <li>Center-specific adaptation layer.</li> </ul>"},{"location":"adr/0015-python-bindings-with-pybind11/","title":"15. Python bindings with pybind11","text":"<p>Date: 2025-10-13</p>"},{"location":"adr/0015-python-bindings-with-pybind11/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"adr/0015-python-bindings-with-pybind11/#context","title":"Context","text":"<p>Researchers and users need a fast scripting and notebook interface.</p>"},{"location":"adr/0015-python-bindings-with-pybind11/#decision","title":"Decision","text":"<p>Expose bindings with pybind11 over the C++ runtime API, limiting Python usage to the edge and avoiding hot data paths.</p>"},{"location":"adr/0015-python-bindings-with-pybind11/#consequences","title":"Consequences","text":"<ul> <li>Easy adoption without penalizing data-plane performance.</li> <li>Requires maintaining wrapper layers.</li> </ul>"},{"location":"adr/0016-no-chapel-charm-or-upc-in-core/","title":"16. No Chapel, Charm++, or UPC in core","text":"<p>Date: 2025-10-13</p>"},{"location":"adr/0016-no-chapel-charm-or-upc-in-core/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"adr/0016-no-chapel-charm-or-upc-in-core/#context","title":"Context","text":"<p>Alternative models offer productivity and dynamic load balancing but add runtime dependencies and heterogeneity.</p>"},{"location":"adr/0016-no-chapel-charm-or-upc-in-core/#decision","title":"Decision","text":"<p>Do not use Chapel, Charm++, or UPC in the core. They remain optional for comparative prototypes or publications. The core stays in C++, MPI, OpenMP, OmpSs-2.</p>"},{"location":"adr/0016-no-chapel-charm-or-upc-in-core/#consequences","title":"Consequences","text":"<ul> <li>Reduced portability complexity.</li> <li>Comparative results documented when relevant.</li> </ul>"},{"location":"adr/0017-nccl-for-multi-gpu-intra-node/","title":"17. NCCL for multi-GPU intra-node","text":"<p>Date: 2025-10-13</p>"},{"location":"adr/0017-nccl-for-multi-gpu-intra-node/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"adr/0017-nccl-for-multi-gpu-intra-node/#context","title":"Context","text":"<p>Contractions and partial reductions require efficient collectives between GPUs in the same node.</p>"},{"location":"adr/0017-nccl-for-multi-gpu-intra-node/#decision","title":"Decision","text":"<p>Use NCCL for intra-node all-reduce and broadcast, coordinated with MPI for inter-node communication.</p>"},{"location":"adr/0017-nccl-for-multi-gpu-intra-node/#consequences","title":"Consequences","text":"<ul> <li>Better utilization of NVLink and GPU topologies.</li> <li>Dual MPI\u2013NCCL management complexity.</li> </ul>"},{"location":"adr/0018-global-arrays-or-openshmem-as-optional/","title":"18. Global Arrays or OpenSHMEM as optional","text":"<p>Date: 2025-10-13</p>"},{"location":"adr/0018-global-arrays-or-openshmem-as-optional/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"adr/0018-global-arrays-or-openshmem-as-optional/#context","title":"Context","text":"<p>One-to-many access bottlenecks may occur in the tensor plane during distributed stitching.</p>"},{"location":"adr/0018-global-arrays-or-openshmem-as-optional/#decision","title":"Decision","text":"<p>Mark Global Arrays or OpenSHMEM as optional features, enabled only if profiling shows performance benefits over MPI RMA.</p>"},{"location":"adr/0018-global-arrays-or-openshmem-as-optional/#consequences","title":"Consequences","text":"<ul> <li>Avoids unnecessary complexity by default.</li> <li>Provides a clear path for advanced optimization.</li> </ul>"},{"location":"adr/0019-qpu-credential-security-and-management/","title":"19. QPU credential security and management","text":"<p>Date: 2025-10-13</p>"},{"location":"adr/0019-qpu-credential-security-and-management/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"adr/0019-qpu-credential-security-and-management/#context","title":"Context","text":"<p>Access to cloud QPU providers requires secure tokens and credentials.</p>"},{"location":"adr/0019-qpu-credential-security-and-management/#decision","title":"Decision","text":"<p>Keep credentials outside the MPI domain in an auxiliary process or in the Apptainer container secret store. Use read-only mounts and scheduled rotation.</p>"},{"location":"adr/0019-qpu-credential-security-and-management/#consequences","title":"Consequences","text":"<ul> <li>Reduced exposure surface.</li> <li>Additional bootstrap and renewal logic.</li> </ul>"},{"location":"adr/0020-containers-and-reproducibility-with-apptainer/","title":"20. Containers and reproducibility with Apptainer","text":"<p>Date: 2025-10-13</p>"},{"location":"adr/0020-containers-and-reproducibility-with-apptainer/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"adr/0020-containers-and-reproducibility-with-apptainer/#context","title":"Context","text":"<p>Reproducibility is required across clusters and lab environments.</p>"},{"location":"adr/0020-containers-and-reproducibility-with-apptainer/#decision","title":"Decision","text":"<p>Distribute binaries and dependencies in Apptainer containers with signed hashes, integrating LMod modules and center toolchains.</p>"},{"location":"adr/0020-containers-and-reproducibility-with-apptainer/#consequences","title":"Consequences","text":"<ul> <li>Portability and reproducibility ensured.</li> <li>Requires recipes and build pipeline in CI.</li> </ul>"},{"location":"adr/0021-benchmark-selection-n2-and-metrics/","title":"21. Benchmark selection: N2 and metrics","text":"<p>Date: 2025-10-13</p>"},{"location":"adr/0021-benchmark-selection-n2-and-metrics/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"adr/0021-benchmark-selection-n2-and-metrics/#context","title":"Context","text":"<p>A representative and measurable case is needed to validate the runtime.</p>"},{"location":"adr/0021-benchmark-selection-n2-and-metrics/#decision","title":"Decision","text":"<p>Use \\(N_2\\) molecule as the main study case, with dissociation curves in manageable bases for 10 minutes of QPU monthly runtime and HPC simulation. Metrics: fidelity \\(F\\), effective depth \\(D_eff\\), speedup \\(S\\), \\(p\\), efficiency \\(E_p\\), complementary occupancy \\(\\chi\\), and approximate energy cost.</p>"},{"location":"adr/0021-benchmark-selection-n2-and-metrics/#consequences","title":"Consequences","text":"<ul> <li>Comparability with recent literature.</li> <li>Solid baseline for evaluation and publication.</li> </ul>"},{"location":"adr/0022-qpu-cloud-usage-limits/","title":"22. QPU cloud usage limits","text":"<p>Date: 2025-10-13</p>"},{"location":"adr/0022-qpu-cloud-usage-limits/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"adr/0022-qpu-cloud-usage-limits/#context","title":"Context","text":"<p>We have limited execution windows on IBM Torino, around 10 minutes per month.</p>"},{"location":"adr/0022-qpu-cloud-usage-limits/#decision","title":"Decision","text":"<p>Reserve the QPU for critical subcircuits with higher fidelity impact and validate representative points. Simulate the remaining circuits on HPC using cuQuantum and Aer.</p>"},{"location":"adr/0022-qpu-cloud-usage-limits/#consequences","title":"Consequences","text":"<ul> <li>Efficient use of quantum time.</li> <li>Limited statistical results from real hardware.</li> </ul>"},{"location":"adr/0023-configuration-and-contracts-in-yaml/","title":"23. Configuration and contracts in YAML","text":"<p>Date: 2025-10-13</p>"},{"location":"adr/0023-configuration-and-contracts-in-yaml/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"adr/0023-configuration-and-contracts-in-yaml/#context","title":"Context","text":"<p>Resources, limits, and policies must be parameterized per job reproducibly.</p>"},{"location":"adr/0023-configuration-and-contracts-in-yaml/#decision","title":"Decision","text":"<p>Use YAML to describe resources, QPU windows, scheduling policies, fidelity limits, and CPU\u2013GPU affinity. Version YAML files along with IR and results.</p>"},{"location":"adr/0023-configuration-and-contracts-in-yaml/#consequences","title":"Consequences","text":"<ul> <li>Execution traceability.</li> <li>Requires validators and schema definitions.</li> </ul>"},{"location":"adr/0024-structured-jsonl-logs-and-wave-ids/","title":"24. Structured JSONL logs and wave IDs","text":"<p>Date: 2025-10-13</p>"},{"location":"adr/0024-structured-jsonl-logs-and-wave-ids/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"adr/0024-structured-jsonl-logs-and-wave-ids/#context","title":"Context","text":"<p>Post-mortem analysis and auditing require machine-readable traces.</p>"},{"location":"adr/0024-structured-jsonl-logs-and-wave-ids/#decision","title":"Decision","text":"<p>Emit JSONL logs with wave and subcircuit IDs, timestamps, latencies, and GPU/MPI counters. Store indexes for fast search.</p>"},{"location":"adr/0024-structured-jsonl-logs-and-wave-ids/#consequences","title":"Consequences","text":"<ul> <li>Production-level observability.</li> <li>Additional disk space for trace data.</li> </ul>"},{"location":"architecture/","title":"Architecture Views Index","text":"<p>This section presents the C4 model architecture views of the hybrid HPCQC stack. Each level refines the system from high-level context to detailed components, deployment topology, and execution scenarios. These diagrams correspond to the software stack layer of the research project \u2014the runtime and middleware that enable practical realization of space\u2013time circuit knitting.</p>"},{"location":"architecture/#c4-model-overview","title":"C4 Model Overview","text":"Level View Description L1 System Context Defines the system boundaries, users, and external services (RMS, QPU cloud). L2 Container View Shows the main software containers: frontends, middleware, runtime, backends, observability. L3-A Component View: Middleware Detailed view of IR manager, partitioner, models, and scheduler. L3-B Component View: Runtime Internal structure of the hybrid runtime and tensor data plane. L2\u2032 Deployment View Typical deployment on HPC clusters (CPU/GPU nodes, RMS, QPU cloud). Scenario N\u2082 Job Sequence Sequence diagram of an end-to-end N\u2082 quantum-chemistry job."},{"location":"architecture/01-system-context/","title":"C4 Level 1 \u2014 System Context","text":"<p>This document shows the context of the hybrid QC\u2013HPC system versus users, QC cloud platforms and the BSC HPC environment.</p>"},{"location":"architecture/01-system-context/#relevant-adrs","title":"Relevant ADRs","text":"<p>2. Product: Hybrid HPCQC middleware and runtime 4. Quantum exchange format: OpenQASM 3 14. RMS integration: Slurm, HyperQueue, PBS 22. QPU cloud usage limits</p> <pre><code>%%{init: {'layout': 'elk', 'theme': 'neutral', 'flowchart': {'useMaxWidth': true}}}%%\nflowchart TB\n  subgraph Users[People and External Systems]\n    U[HPC QC Users]\n    QCCloud[QPU Cloud Providers]\n    RMS[HPC RMS Slurm HyperQueue PBS]\n  end\n\n  subgraph System[Hybrid QC HPC System]\n    FE[CLI and Python bindings]\n    Core[Hybrid Middleware and Runtime]\n  end\n\n  U -- submit circuits configs monitor --&gt; FE\n  FE -- validated inputs and contracts --&gt; Core\n  Core -- job requests allocations --&gt; RMS\n  Core -- QASM3 jobs telemetry --&gt; QCCloud\n  QCCloud -- bitstrings calib status --&gt; Core\n  RMS -- resources and scheduling --&gt; Core</code></pre>"},{"location":"architecture/01-system-context/#scope","title":"Scope","text":"<ul> <li>The user submits circuits and configuration to the CLI or Python bindings.</li> <li>The middleware and runtime orchestrate HPC and QPU cloud resources.</li> <li>The BSC RMS allocates CPU and GPU resources.</li> <li>QC providers execute subcircuits and return results.</li> </ul>"},{"location":"architecture/02-container/","title":"C4 Level 2 \u2014 Container View","text":"<p>Decomposes the system into logical containers: frontends, middleware, runtime, backends, and observability.</p>"},{"location":"architecture/02-container/#relevant-adrs","title":"Relevant ADRs","text":"<p>3. Base language and toolchain: C++17 + MPI + CUDA 5. QASM3 parser with ANTLR4 in C++ 6. Internal IR: space\u2013time DAG with annotations 10. QPU transport and backends: REST gRPC 13. Observability: logging, metrics, and profiling</p> <pre><code>%%{init: {'layout': 'elk', 'theme': 'neutral', 'flowchart': {'useMaxWidth': true}}}%%\nflowchart TB\n  subgraph Frontends\n    CLI[CLI]\n    PY[Python bindings]\n    PARSER[QASM3 Parser C++ ANTLR]\n  end\n\n  subgraph Core[Middleware and Runtime]\n    IR[IR Space Time DAG]\n    PART[Partitioner wire cuts time cuts]\n    M1M2[Cost and Fidelity Models]\n    SCHED[Malleable HEFT Scheduler]\n    RT[Runtime API submit run collect]\n    DATA[Data Plane shots tensors]\n  end\n\n  subgraph HPC[HPC Execution]\n    MPI[MPI]\n    GPU[CUDA cuBLAS cuTensorNet NCCL]\n    IO[HDF5 with MPI IO]\n  end\n\n  subgraph QC[Quantum Execution]\n    QTR[Transport REST gRPC]\n    QPU[QPU Cloud Backends]\n    SIM[Simulators cuQuantum Aer]\n  end\n\n  subgraph OBS[Observability]\n    LOG[JSONL Logs]\n    MET[Metrics S p Ep chi Fidelity]\n    PROF[Profiling Nsight mpiP Scalasca]\n  end\n\n  CLI --&gt; PARSER\n  PY --&gt; RT\n  PARSER --&gt; IR\n  IR --&gt; PART\n  PART --&gt; M1M2\n  M1M2 --&gt; SCHED\n  SCHED --&gt; RT\n  RT --&gt; DATA\n  RT --&gt; QTR\n  RT --&gt; MPI\n  DATA --&gt; GPU\n  GPU --&gt; IO\n  QTR --&gt; QPU\n  RT --&gt; SIM\n  OBS --- Core\n  Core --&gt; MET\n  Core --&gt; LOG\n  GPU --&gt; PROF\n  MPI --&gt; PROF</code></pre>"},{"location":"architecture/02-container/#interfaces","title":"Interfaces","text":"<ul> <li>Frontend to Core: QASM3 contracts and YAML.</li> <li>Core to HPC: MPI and CUDA kernels.</li> <li>Core to QC: REST gRPC with QASM3.</li> <li>Lateral observability with metric logs and profiling.</li> </ul>"},{"location":"architecture/03-components-middleware/","title":"C4 Level 3 \u2014 Component View: Middleware","text":"<p>Internal Middleware components: IR, Partitioner, M1 M2 Models, Scheduler, and RMS adapters.</p>"},{"location":"architecture/03-components-middleware/#relevant-adrs","title":"Relevant ADRs","text":"<p>6. Internal IR: space\u2013time DAG with annotations 7. Partition policy: wire cuts and time cuts 8. Cost and fidelity model 9. Malleable HEFT scheduler 14. RMS integration: Slurm, HyperQueue, PBS</p> <pre><code>%%{init: {'layout': 'elk', 'theme': 'neutral', 'flowchart': {'useMaxWidth': true}}}%%\nflowchart TB\n  subgraph MW[Middleware]\n    IR[IR Manager]\n    ANA[Static Analysis depth twoQ layout]\n    CUTS[Partitioner low correlation wire time cuts]\n    MODELS[M1 Cost M2 Fidelity]\n    PLAN[Planner HEFT with critical path]\n    RMSA[RMS Adapter Slurm HyperQueue PBS]\n  end\n\n  IR --&gt; ANA\n  ANA --&gt; CUTS\n  CUTS --&gt; MODELS\n  MODELS --&gt; PLAN\n  PLAN --&gt; RMSA\n  PLAN --&gt;|wave plan| RuntimeAPI\n  MODELS --&gt;|feedback| OBS\n\n  RuntimeAPI[Runtime API]\n  OBS[Metrics and Profiling]</code></pre>"},{"location":"architecture/03-components-middleware/#design-notes","title":"Design Notes","text":"<ul> <li>IR Manager ensures traceability and serialization for reproducibility.</li> <li>Partitioner applies cross-2Q counting heuristics and entropy estimators.</li> <li>Planner uses modified HEFT with \\(T_q,\\,T_c,\\,\\text{Comm}\\) and a \\(\\Delta_F\\) penalty.</li> </ul>"},{"location":"architecture/04-components-runtime/","title":"C4 Level 3 \u2014 Component View: Runtime","text":"<p>Breakdown of the execution runtime and its data plane.</p>"},{"location":"architecture/04-components-runtime/#relevant-adrs","title":"Relevant ADRs","text":"<p>3. Base language and toolchain: C++17 + MPI + CUDA 10. QPU transport and backends: REST gRPC 11. Tensor contraction stitching: cuBLAS and cuTensorNet 12. Storage and checkpointing: HDF5 with MPI-IO 17. NCCL for multi-GPU intra-node</p> <pre><code>%%{init: {'layout': 'elk', 'theme': 'neutral', 'flowchart': {'useMaxWidth': true}}}%%\nflowchart TB\n  subgraph RT[Runtime]\n    API[API C++ submit collect]\n    QUEUE[Task DAG Queue]\n    TX[QPU Transport REST gRPC]\n    DMA[Data Plane buffers pinned]\n    CKPT[Checkpoint HDF5]\n  end\n\n  subgraph HPC[HPC Exec]\n    MPIC[MPI World and Teams]\n    OMP[OpenMP OmpSs 2]\n    CUDA[CUDA Kernels]\n    CUBLAS[cuBLAS]\n    CUTN[cuTensorNet]\n    NCCL[NCCL Collectives]\n  end\n\n  subgraph QExec[Quantum Exec]\n    QPU[QPU Cloud]\n    SIM[Simulators cuQuantum Aer]\n  end\n\n  API --&gt; QUEUE\n  QUEUE --&gt; TX\n  QUEUE --&gt; MPIC\n  DMA --&gt; CUDA\n  CUDA --&gt; CUBLAS\n  CUDA --&gt; CUTN\n  CUTN --&gt; NCCL\n  MPIC --&gt; CUTN\n  CUTN --&gt; CKPT\n  TX --&gt; QPU\n  API --&gt; SIM\n  SIM --&gt; DMA\n  QPU --&gt; DMA\n  CKPT --&gt; API</code></pre>"},{"location":"architecture/04-components-runtime/#responsibilities","title":"Responsibilities","text":"<ul> <li>API exposes submit and collect.</li> <li>Task DAG Queue maintains dependencies.</li> <li>Data Plane manages shots and tensors with pinned buffers.</li> <li>cuTensorNet performs stitching and uses NCCL for collectives.</li> </ul>"},{"location":"architecture/05-deployment/","title":"C4 Level 2 \u2014 Deployment View","text":"<p>Deployment topology with CPU, GPU nodes and connection to QPU/QPU cloud.</p>"},{"location":"architecture/05-deployment/#relevant-adrs","title":"Relevant ADRs","text":"<p>20. Containers and reproducibility with Apptainer 19. QPU credential security and management 14. RMS integration: Slurm, HyperQueue, PBS</p> <pre><code>%%{init: {'layout': 'elk', 'theme': 'neutral', 'flowchart': {'useMaxWidth': true}}}%%\nflowchart TB\n  subgraph BSC[HPC Cluster]\n    subgraph Head[Head node]\n      RMS[Slurm Controller]\n      Registry[Artifact Registry]\n    end\n    subgraph Compute[Compute nodes]\n      CPU1[CPU node x N]\n      GPU1[GPU node x M]\n    end\n  end\n\n  subgraph Cloud[Quantum Cloud]\n    QGateways[Provider API Gateways]\n    QPUs[Managed QPU endpoints]\n  end\n\n  Dev[Developer Workstation] --&gt; Registry\n  Registry --&gt; Head\n  RMS --&gt; CPU1\n  RMS --&gt; GPU1\n  GPU1 --&gt; QGateways\n  QGateways --&gt; QPUs</code></pre>"},{"location":"architecture/05-deployment/#deployment","title":"Deployment","text":"<ul> <li>Binaries packaged in Apptainer.</li> <li>QPU credentials managed outside the MPI world according to ADR 0019.</li> <li>Heterogeneous CPU GPU queues and QPU windows coordinated by the middleware.</li> </ul>"},{"location":"architecture/06-sequence-n2-job/","title":"C4 Scenario \u2014 \\(N_2\\) Job Sequence","text":"<p>High-level sequence for a simulation job of the \\(N_2\\) molecule from submission to reconstruction.</p>"},{"location":"architecture/06-sequence-n2-job/#relevant-adrs","title":"Relevant ADRs","text":"<p>6. Internal IR: space\u2013time DAG with annotations 7. Partition policy: wire cuts and time cuts 9. Malleable HEFT scheduler 11. Tensor contraction stitching: cuBLAS and cuTensorNet 13. Observability: logging, metrics, and profiling</p> <pre><code>%%{init: {'layout': 'elk', 'theme': 'neutral', 'flowchart': {'useMaxWidth': true}}}%%\nsequenceDiagram\n  autonumber\n  participant User as User\n  participant CLI as CLI\n  participant Parser as QASM3 Parser\n  participant IR as IR Manager\n  participant Part as Partitioner\n  participant Plan as HEFT Scheduler\n  participant RT as Runtime\n  participant MPI as MPI Teams\n  participant CUTN as cuTensorNet\n  participant QPU as QPU Cloud\n  participant SIM as Simulator\n  participant HDF5 as HDF5 Store\n  participant OBS as Observability O2 O3\n\n  User-&gt;&gt;CLI: submit $N_2$ job with QASM3 and YAML\n  CLI-&gt;&gt;Parser: validate and normalize\n  Parser-&gt;&gt;IR: build space time DAG with metadata\n  IR-&gt;&gt;Part: low correlation bipartitions and time layers\n  Part-&gt;&gt;Plan: subcircuits with M1 cost and M2 fidelity bounds\n  Plan-&gt;&gt;RT: wave plan and team sizes\n  RT-&gt;&gt;MPI: create dynamic teams\n  par classical wave\n    RT-&gt;&gt;MPI: launch classical subcircuits\n    MPI-&gt;&gt;CUTN: tensor kernels\n    CUTN-&gt;&gt;HDF5: partial results and checkpoints\n  and quantum wave\n    RT-&gt;&gt;QPU: send QASM3 fragments\n    QPU-&gt;&gt;RT: bitstrings and calib data\n    RT-&gt;&gt;HDF5: persist shots\n  end\n  RT-&gt;&gt;CUTN: stitching contraction\n  CUTN-&gt;&gt;RT: observables and rho\n  RT-&gt;&gt;OBS: metrics and traces\n  RT-&gt;&gt;CLI: final results and artifacts</code></pre>"},{"location":"architecture/06-sequence-n2-job/#results","title":"Results","text":"<ul> <li>Observables and fidelity of \\(N_2\\).</li> <li>JSONL traces and O2 O3 profiles.</li> <li>Reproducible HDF5 checkpoints.</li> </ul>"},{"location":"rfc/","title":"RFC Index","text":"<p>This section contains all Request for Comments (RFC) documents that complement and extend the subsystems and protocols of the software stack. Each RFC complements the ADRs by defining how each architectural decision (for example, algorithms or interfaces) is implemented or technically specified.</p>"},{"location":"rfc/#core-specifications","title":"Core Specifications","text":"<ul> <li>RFC-01: IR Specification and Serialization Contract</li> <li>RFC-02: Runtime API and YAML Contracts</li> </ul>"},{"location":"rfc/#execution-and-scheduling","title":"Execution and Scheduling","text":"<ul> <li>RFC-03: Malleable HEFT Scheduler and Resizing Rules</li> <li>RFC-04: Tensor Stitching and GPU Data Layout</li> </ul>"},{"location":"rfc/#observability-and-feedback","title":"Observability and Feedback","text":"<ul> <li>RFC-05: Observability and M\u2081\u2013M\u2082 Feedback Loop</li> </ul>"},{"location":"rfc/#security-and-compliance","title":"Security and Compliance","text":"<ul> <li>RFC-06: QPU Credential Security and Threat Model</li> </ul>"},{"location":"rfc/#deployment-and-operations","title":"Deployment and Operations","text":"<ul> <li>RFC-07: Deployment and Operations on HPC\u2013QC Systems</li> </ul>"},{"location":"rfc/#validation-and-benchmarking","title":"Validation and Benchmarking","text":"<ul> <li>RFC-08: Scientific Validation and Benchmarking (\\(N_2\\) Case)</li> </ul>"},{"location":"rfc/#notes","title":"Notes","text":"<ul> <li>RFCs are living documents subject to revision until the prototype phase.</li> <li>Each RFC is versioned and cross-referenced to its related ADRs.</li> <li>Once implementation begins, additional RFCs will cover:</li> <li>SBOM and dependency traceability</li> <li>CI/CD and testing strategy</li> <li>RACI matrices for engineering governance</li> </ul>"},{"location":"rfc/01-ir-spec/","title":"RFC-01: IR Specification and Serialization Contract","text":"<p>Date: 2025-10-18 Status: Proposed Owner: Ricard Santiago Raigada Garc\u00eda</p>"},{"location":"rfc/01-ir-spec/#adr-links","title":"ADR Links","text":"<p>#4 OpenQASM 3 #5 QASM3 Parser #6 Internal IR </p>"},{"location":"rfc/01-ir-spec/#motivation","title":"Motivation","text":"<p>Middleware between HPC and QC requires an intermediate representation that expresses quantum-classical dependencies, spatiotemporal structure, and cost metadata. OpenQASM 3 provides the syntax and is nearly standard across many technologies, but does not provide operational semantics. This RFC defines a stable, versioned IR (Intermediate Representation), used internally for partitioning, scheduling, and reproducibility.</p>"},{"location":"rfc/01-ir-spec/#scope","title":"Scope","text":"<ul> <li>Logical and data model of the IR</li> <li>Serialization and versioning policy</li> <li>Validation and compatibility rules</li> <li>Excludes backend-specific transpilation</li> </ul>"},{"location":"rfc/01-ir-spec/#design-overview","title":"Design Overview","text":"<p>Each circuit is parsed into a space-time DAG:</p> <ul> <li>Node: represents a quantum or classical operation <code>id, type, qubits, cvars, time_index, deps, cost, fidelity_est, metadata</code></li> <li>Edge: dependency (temporal or data)</li> <li>Annotations: <code>space</code> labels identify qubit partitions <code>time</code> labels identify temporal slices or trotterized steps  </li> <li>Metadata: <code>depth</code>, <code>2Qcount</code>, <code>layout</code>, <code>error_rate</code></li> </ul>"},{"location":"rfc/01-ir-spec/#invariants","title":"Invariants","text":"<ul> <li>DAG is acyclic</li> <li><code>time_index</code> is non-decreasing along edges</li> <li>Space labels form a full partition of qubits</li> <li>All nodes carry cost fields compatible with M1 model</li> </ul>"},{"location":"rfc/01-ir-spec/#serialization","title":"Serialization","text":"<p>Primary format: JSON Schema Each file includes a <code>ir_version</code> field (semver). Example:</p> <pre><code>{\n  \"ir_version\":\"1.0.0\",\n  \"nodes\":[\n    {\"id\":1,\"type\":\"cx\",\"qubits\":[0,1],\"space\":\"s0\",\"time\":0,\n     \"cost\":{\"Tq\":0.15,\"Tc\":0,\"Comm\":0},\"deps\":[]}\n  ]\n}\n</code></pre>"},{"location":"rfc/01-ir-spec/#versioning-policy","title":"Versioning Policy","text":"<p>Minor versions add optional fields with defaults. Breaking changes increment the major version. Migration scripts provided under <code>tools/ir_migrate</code>.</p>"},{"location":"rfc/01-ir-spec/#rationale","title":"Rationale","text":"<p>A custom IR avoids dependence on LLVM/MLIR while capturing hybrid semantics relevant to space\u2013time circuit knitting.</p>"},{"location":"rfc/01-ir-spec/#risks","title":"Risks","text":"<ul> <li>Divergence from QIR standard if community evolves quickly.</li> <li>Parser upgrades must preserve compatibility.</li> </ul>"},{"location":"rfc/01-ir-spec/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>IR validates under schema and round-trips from and to QASM3 without loss.</li> <li>Partitioning and scheduling operate solely on IR data.</li> </ul>"},{"location":"rfc/02-runtime-api/","title":"RFC-02: Runtime API and YAML Contracts","text":"<p>Date: 2025-10-18 Status: Proposed Owner: Ricard Santiago Raigada Garc\u00eda</p>"},{"location":"rfc/02-runtime-api/#adr-links","title":"ADR Links","text":"<p>#2 Product #15 Python bindings #23 Configuration YAML</p>"},{"location":"rfc/02-runtime-api/#motivation","title":"Motivation","text":"<p>The API must expose dispatch, monitoring, and collection semantics consistently across the C++ and Python bindings\u2014whenever a high-level interface is deemed necessary. Therefore, a clear contract is required between user applications and the hybrid runtime environment.</p>"},{"location":"rfc/02-runtime-api/#scope","title":"Scope","text":"<ul> <li>C++23 API surface and Python mirror  </li> <li>YAML job-spec schema  </li> <li>Error states and lifecycle  </li> </ul>"},{"location":"rfc/02-runtime-api/#design","title":"Design","text":""},{"location":"rfc/02-runtime-api/#c-api","title":"C++ API","text":"<pre><code>class Runtime {\n public:\n   JobId submit(const YamlConfig&amp; config, const IRGraph&amp; ir);\n   JobStatus query(JobId id) const;\n   Result collect(JobId id);\n   void cancel(JobId id);\n};\n</code></pre>"},{"location":"rfc/02-runtime-api/#python-binding","title":"Python Binding","text":"<p>Generated via <code>pybind11</code>; one-to-one method exposure.</p>"},{"location":"rfc/02-runtime-api/#yaml-contract","title":"YAML Contract","text":"<pre><code>job:\n  name: N2-benchmark\n  backend: ibm_torino\n  waves: 2\nresources:\n  cpus: 32\n  gpus: 4\n  memory_gb: 128\n  qpu_window: \"00:05:00\"\nmodels:\n  alpha: 0.6\n  beta: 0.3\n  gamma: 0.1\nfidelity:\n  max_deltaF: 0.02\n</code></pre>"},{"location":"rfc/02-runtime-api/#job-lifecycle","title":"Job Lifecycle","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; SUBMITTED\n    SUBMITTED --&gt; QUEUED\n    QUEUED --&gt; RUNNING\n    RUNNING --&gt; STITCHING\n    STITCHING --&gt; COMPLETED\n    QUEUED --&gt; FAILED\n    RUNNING --&gt; FAILED</code></pre>"},{"location":"rfc/02-runtime-api/#error-semantics","title":"Error Semantics","text":"<ul> <li><code>ValidationError</code>: malformed YAML or IR</li> <li><code>ResourceError</code>: RMS allocation failure</li> <li><code>TransportError</code>: QPU endpoint unreachable</li> <li><code>StitchError</code>: tensor contraction failure</li> </ul>"},{"location":"rfc/02-runtime-api/#rationale","title":"Rationale","text":"<p>Explicit contracts simplify orchestration workflows (Snakemake/Nextflow) and enable deterministic replay.</p>"},{"location":"rfc/02-runtime-api/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>CLI and Python bindings share a single code path.</li> <li>Runtime state machine reproducible in integration tests.</li> </ul>"},{"location":"rfc/03-scheduler-heft-malleability/","title":"RFC-03: Malleable HEFT Scheduler and Resizing Rules","text":"<p>Date: 2025-10-18 Status: Proposed Owner: Ricard Santiago Raigada Garc\u00eda</p>"},{"location":"rfc/03-scheduler-heft-malleability/#adr-links","title":"ADR Links","text":"<p>#8 Cost and Fidelity Model #9 Malleable HEFT Scheduler #14 RMS Integration</p>"},{"location":"rfc/03-scheduler-heft-malleability/#motivation","title":"Motivation","text":"<p>Hybrid subcircuits differ in cost composition (\\(T_q,\\, T_c,\\, \\text{Comm}\\)). The scheduler must minimize total makespan while overlapping HPC and QPU work, adjusting dynamically to resource availability.</p>"},{"location":"rfc/03-scheduler-heft-malleability/#scope","title":"Scope","text":"<p>Defines the modified HEFT algorithm, malleability model, resizing policies, and rescheduling triggers.</p>"},{"location":"rfc/03-scheduler-heft-malleability/#algorithm-design","title":"Algorithm Design","text":"<p>Base algorithm: HEFT (Heterogeneous Earliest Finish Time) Modifications:</p> <ul> <li>Composite cost model: \\(C(v) = \\alpha \\cdot T_q(v) + \\beta \\cdot T_c(v) + \\gamma \\cdot \\text{Comm}(v)\\)</li> <li>Window awareness: penalties when QPU slot unavailable</li> <li>Dynamic teams: create/destroy MPI communicators (<code>MPI_Comm_split</code>)</li> <li>Energy-aware policy: global power cap and cost feedback</li> <li>Re-scheduling: triggered by deviations reported by O2/O3 modules</li> </ul>"},{"location":"rfc/03-scheduler-heft-malleability/#priority-computation","title":"Priority Computation","text":"<p>Each node receives rank u (upward) based on critical path length using M1 costs. Tasks scheduled in descending rank u, earliest start respecting dependencies.</p>"},{"location":"rfc/03-scheduler-heft-malleability/#malleability-rules","title":"Malleability Rules","text":"<ul> <li>Teams resized at wave boundaries only.</li> <li>Minimum dwell time between resizes \\(= 2\\,\\times\\) average \\(T_q\\).</li> <li>Resizing favored when occupancy \\(\\chi &lt; 0.7\\) or GPU idle \\(&gt; 20 \\%\\).</li> <li>Team creation limited by RMS quotas.</li> </ul>"},{"location":"rfc/03-scheduler-heft-malleability/#pseudocode","title":"Pseudocode","text":"<pre><code>for wave in ready_waves:\n  ranks = sort_by_rank_u(wave)\nfor task in ranks:\n  device = select_best_resource(task)\n  schedule(task, device)\n  update_teams(O2.metrics)\n</code></pre>"},{"location":"rfc/03-scheduler-heft-malleability/#telemetry-integration","title":"Telemetry Integration","text":"<p>O2 supplies \\(\\chi,\\, E_p,\\, p\\); O3 supplies Comm and GPU utilization. Weights (\\(\\alpha,\\, \\beta,\\, \\gamma\\)) recalibrated periodically.</p>"},{"location":"rfc/03-scheduler-heft-malleability/#risks","title":"Risks","text":"<ul> <li>Parameter sensitivity may cause oscillations.  </li> <li>Re-sizing overhead on large MPI worlds.</li> </ul>"},{"location":"rfc/03-scheduler-heft-malleability/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Idle HPC time reduced \u2265 30 %.  </li> <li>Complementary occupancy \u03c7 \u2265 0.8.  </li> <li>Scheduler overhead \u2264 2 % of runtime.</li> </ul>"},{"location":"rfc/04-stitching-tensor-data-layout/","title":"RFC-04: Tensor Stitching and GPU Data Layout","text":"<p>Date: 2025-10-18 Status: Proposed Owner: Ricard Santiago Raigada Garc\u00eda</p>"},{"location":"rfc/04-stitching-tensor-data-layout/#adr-links","title":"ADR Links","text":"<p>#11 Tensor Contraction Stitching #12 Storage and Checkpointing #17 NCCL Multi-GPU</p>"},{"location":"rfc/04-stitching-tensor-data-layout/#motivation","title":"Motivation","text":"<p>Efficient stitching after circuit cuts depends on tensor layout, GPU memory management, and distributed reductions. We must maximize throughput and numerical stability.</p>"},{"location":"rfc/04-stitching-tensor-data-layout/#scope","title":"Scope","text":"<p>Covers data layout, GPU parallelism, checkpointing and recovery. Excludes quantum-algorithm logic.</p>"},{"location":"rfc/04-stitching-tensor-data-layout/#data-layout-policy","title":"Data Layout Policy","text":"<ul> <li>Row-major storage with stride order following qubit index.</li> <li>Batched contractions fused when index overlap &gt; 50 %.</li> <li>Use half-precision (FP16) when fidelity impact &lt; 1 e-3.</li> <li>Pin buffers in unified memory for async GPU transfers.</li> </ul>"},{"location":"rfc/04-stitching-tensor-data-layout/#gpu-parallelism","title":"GPU Parallelism","text":"<ul> <li>cuTensorNet for contraction planning and execution.</li> <li>cuBLAS for small dense blocks.</li> <li>NCCL AllReduce for intra-node aggregation.</li> <li>MPI Iallreduce for inter-node fusion of boundary tensors.</li> </ul>"},{"location":"rfc/04-stitching-tensor-data-layout/#checkpointing","title":"Checkpointing","text":"<ul> <li>HDF5 datasets with chunk size = 128 MB; compression gzip 4.</li> <li>Metadata group per wave: time, fidelity_est, alpha_beta_gamma.</li> <li>Checkpoints restartable and replayable for regression testing.</li> </ul>"},{"location":"rfc/04-stitching-tensor-data-layout/#rationale","title":"Rationale","text":"<p>Explicit data-layout control reduces GPU \\(\\rightarrow\\) CPU traffic and guarantees reproducibility across architectures.</p>"},{"location":"rfc/04-stitching-tensor-data-layout/#risks","title":"Risks","text":"<ul> <li>Half-precision accumulation may affect observables &gt; target \\(\\Delta_F\\).</li> <li>Large tensor graphs may exceed GPU memory; requires slicing.</li> </ul>"},{"location":"rfc/04-stitching-tensor-data-layout/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Stitching throughput \\(\\geq 85 %\\) of cuTensorNet theoretical.</li> <li>Reconstructed fidelity \\(F \\geq 0.95\\) vs monolithic simulation.</li> <li>Restart from checkpoint restores state bit-exact within tolerance \\(1e-6\\).</li> </ul>"},{"location":"rfc/05-observability-feedback/","title":"RFC-05: Observability and M1\u2013M2 Feedback Loop","text":"<p>Date: 2025-10-18 Status: Proposed Owner: Ricard Santiago Raigada Garc\u00eda</p>"},{"location":"rfc/05-observability-feedback/#adr-links","title":"ADR Links","text":"<p>#8 Cost and Fidelity Model #13 Observability Logging Metrics and Profiling</p>"},{"location":"rfc/05-observability-feedback/#motivation","title":"Motivation","text":"<p>To validate and recalibrate models M1 (cost) and M2 (fidelity), the runtime requires continuous telemetry from modules O2 and O3. Observability enables evidence-based adaptation of scheduling and fidelity bounds.</p>"},{"location":"rfc/05-observability-feedback/#scope","title":"Scope","text":"<p>Defines metrics, telemetry collection, feedback integration, and update rules for \\(\\alpha,\\, \\beta,\\,\\gamma,\\,\\Delta F\\).</p>"},{"location":"rfc/05-observability-feedback/#components","title":"Components","text":"<ul> <li>O2 Metrics Aggregator \u2014 computes \\(S,\\, p,\\, E_p,\\, \\chi,\\, F\\) from logs.  </li> <li>O3 Profilers \u2014 Nsight Systems, mpiP, Scalasca produce traces   for GPU utilization, Comm costs, synchronization imbalance.  </li> <li>Telemetry Bus \u2014 JSONL streams merged into HDF5 datasets.  </li> <li>Feedback Engine \u2014 adjusts M1/M2 parameters each \\(N\\) waves.</li> </ul>"},{"location":"rfc/05-observability-feedback/#feedback-algorithm","title":"Feedback Algorithm","text":"<ol> <li>Collect mean \\(T_q\\), \\(T_c\\), and \\(\\mathrm{Comm}\\) from O3 traces.</li> <li>Compute \\(\\chi\\) and \\(p\\) from O2.</li> <li>Update weights:</li> <li>\\(\\alpha \\leftarrow \\alpha \\times \\bigl(1 + \\frac{\\Delta T_q}{T_{q,\\mathrm{ref}}}\\bigr)\\)</li> <li>\\(\\beta \\leftarrow \\beta \\times \\bigl(1 + \\frac{\\Delta T_c}{T_{c,\\mathrm{ref}}}\\bigr)\\)</li> <li>\\(\\gamma \\leftarrow \\gamma \\times \\bigl(1 + \\frac{\\Delta \\mathrm{Comm}}{\\mathrm{Comm}_{\\mathrm{ref}}}\\bigr)\\)</li> <li>If observed \\(\\Delta F &gt; \\Delta F_{\\mathrm{bound}}\\) \u2192 tighten \\(\\Delta F\\) by factor \\(0.9\\).</li> <li>Notify scheduler for next wave plan.</li> </ol>"},{"location":"rfc/05-observability-feedback/#data-retention","title":"Data Retention","text":"<ul> <li>Logs kept 90 days.</li> <li>Metrics aggregated hourly.</li> <li>Sensitive data anonymized before export.</li> </ul>"},{"location":"rfc/05-observability-feedback/#risks","title":"Risks","text":"<ul> <li>Over-frequent recalibration may destabilize scheduling.  </li> <li>Profiling overhead if Nsight sampling &gt; 10 %.  </li> </ul>"},{"location":"rfc/05-observability-feedback/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Telemetry overhead &lt; 3 % runtime.  </li> <li>M1 prediction error &lt; 10 % of measured times.  </li> <li>\\(\\Delta F\\) prediction error &lt; 0.01 absolute.</li> </ul>"},{"location":"rfc/06-security-credentials/","title":"RFC-06: QPU Credential Security and Threat Model","text":"<p>Date: 2025-10-18 Status: Proposed Owner: Ricard Santiago Raigada Garc\u00eda</p>"},{"location":"rfc/06-security-credentials/#adr-links","title":"ADR Links","text":"<p>#19 QPU Credential Security #20 Containers and Reproducibility</p>"},{"location":"rfc/06-security-credentials/#motivation","title":"Motivation","text":"<p>Access to QPU cloud providers requires authentication tokens. These credentials must remain isolated from MPI processes and logs while ensuring usability for automated runs.</p>"},{"location":"rfc/06-security-credentials/#threat-model","title":"Threat Model","text":"Asset Threat Mitigation QPU API tokens Exposure via logs Redact before persistence Network calls MITM attack TLS 1.3, pinned certs Container image Tampering Signed Apptainer SIF Host filesystem Token leakage Read-only mount, ephemeral store"},{"location":"rfc/06-security-credentials/#design","title":"Design","text":"<ul> <li>Secrets mounted in <code>/run/secrets/qpu/</code> inside container, mode 0400.</li> <li>Each MPI rank uses helper daemon to request token via Unix socket.</li> <li>Tokens valid \u2264 15 min; refreshed via short-lived service account.</li> <li>No environment variables with secrets.</li> <li>Logging subsystem filters <code>Authorization</code> headers automatically.</li> </ul>"},{"location":"rfc/06-security-credentials/#risks","title":"Risks","text":"<ul> <li>Token refresh failures may abort long runs.</li> <li>Need coordination with RMS when re-launching container.</li> </ul>"},{"location":"rfc/06-security-credentials/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>No credentials present in any HDF5 or JSONL artifacts.</li> <li>Successful automated refresh in \u2265 99 % of sessions.</li> <li>Zero open findings in periodic container scan.</li> </ul>"},{"location":"rfc/07-deployment-operations/","title":"RFC-07: Deployment and Operations on HPCQC Systems","text":"<p>Date: 2025-10-18 Status: Proposed Owner: Ricard Santiago Raigada Garc\u00eda</p>"},{"location":"rfc/07-deployment-operations/#adr-links","title":"ADR Links","text":"<p>#20 Containers and Reproducibility #14 RMS Integration</p>"},{"location":"rfc/07-deployment-operations/#motivation","title":"Motivation","text":"<p>To ensure reproducibility and operability within the HPC cluster, deployment, and operational processes must be standardized.</p>"},{"location":"rfc/07-deployment-operations/#deployment-architecture","title":"Deployment Architecture","text":"<ul> <li>Containerized runtime built with Apptainer SIF images.</li> <li>Modules managed through LMod.</li> <li>Continuous integration via GitLab Runner on a staging node.</li> <li>RMS backends: Slurm primary, HyperQueue/PBS optional.</li> </ul>"},{"location":"rfc/07-deployment-operations/#build-pipeline","title":"Build Pipeline","text":"<ol> <li>Compile with <code>CMake</code> and <code>NVCC 12</code>.</li> <li>Run unit tests under <code>ctest</code>.</li> <li>Package SIF image with checksum and signature.</li> <li>Publish to internal registry <code>hpc-registry.local/quantum/</code>.</li> </ol>"},{"location":"rfc/07-deployment-operations/#job-submission-example","title":"Job Submission Example","text":"<pre><code>srun --mpi=pmix -N4 -G4 apptainer exec qc_runtime.sif ./hybrid_job.yaml\n</code></pre>"},{"location":"rfc/07-deployment-operations/#monitoring-alerts","title":"Monitoring &amp; Alerts","text":"<ul> <li>Logs streamed to <code>Elastic</code> via JSONL collector.</li> <li>Node energy metrics integrated with HPC telemetry bus.</li> <li>Alert thresholds: job stall &gt; 5 min, QPU latency \\(&gt; 2 \\, \\times\\) median.</li> </ul>"},{"location":"rfc/07-deployment-operations/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Build reproducible from commit hash.</li> <li>End-to-end deployment &lt; 30 min.</li> <li>All jobs traceable by unique wave ID.</li> </ul>"},{"location":"rfc/08-validation-n2-benchmark/","title":"RFC-08: Scientific Validation and Benchmarking (N\u2082 Case)","text":"<p>Date: 2025-10-18 Status: Proposed Owner: Ricard Santiago Raigada Garc\u00eda</p>"},{"location":"rfc/08-validation-n2-benchmark/#adr-links","title":"ADR Links","text":"<p>#21 Benchmark Selection N\u2082</p>"},{"location":"rfc/08-validation-n2-benchmark/#motivation","title":"Motivation","text":"<p>Validation must demonstrate that the hybrid system reproduces quantum-chemical observables of molecular nitrogen \\(\\mathrm{N_2}\\) within acceptable error bounds compared to reference simulations.</p>"},{"location":"rfc/08-validation-n2-benchmark/#benchmark-definition","title":"Benchmark Definition","text":"<ul> <li>Basis set: STO-3G</li> <li>Number of orbitals: 6  </li> <li>Hamiltonian mapped via Jordan\u2013Wigner</li> <li>Expected ground-state energy: \\(E_0 = -108.988\\,\\mathrm{Ha}\\)</li> </ul>"},{"location":"rfc/08-validation-n2-benchmark/#procedure","title":"Procedure","text":"<ol> <li>Generate circuit with Qiskit.</li> <li>Export to QASM3 and ingest into hybrid runtime.  </li> <li>Partition into \\(k\\) spatial and \\(m\\) temporal layers.  </li> <li>Execute classical contractions on HPC nodes; quantum waves on QPU cloud.  </li> <li>Reconstruct density matrix \u03c1 and compute observables.</li> </ol>"},{"location":"rfc/08-validation-n2-benchmark/#metrics","title":"Metrics","text":"<ul> <li>Energy deviation \\(|E - E_0| &lt; 10^{-3}\\,\\mathrm{Ha}\\)</li> <li>Fidelity \\(F(\u03c1,\u03c1_{\\text{ref}}) &gt; 0.95\\)</li> <li>Speedup \\(S = T_{\\text{mono}} / T_{\\text{hybrid}} &gt; 1.5\\)</li> <li>Complementary occupancy \\(\\chi &gt; 0.8\\)</li> </ul>"},{"location":"rfc/08-validation-n2-benchmark/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>All metrics satisfied in \u2265 3 consecutive runs.  </li> <li>Results reproducible with identical IR hash.  </li> <li>Benchmark documented and versioned under <code>/benchmarks/N2</code>.</li> </ul>"}]}